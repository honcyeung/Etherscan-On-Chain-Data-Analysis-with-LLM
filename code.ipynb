{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa459fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    ETHERSCAN_API_KEY = os.getenv(\"ETHERSCAN_API_KEY\")\n",
    "    MODEL = \"gpt-4o-mini\"\n",
    "    AZURE_API_KEY = os.getenv(\"AZURE_API_KEY\")\n",
    "    AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")\n",
    "    AZURE_API_VERSION = os.getenv(\"AZURE_API_VERSION\")\n",
    "    PROMPTLAYER_API_KEY = os.getenv(\"PROMPTLAYER_API_KEY\")\n",
    "except KeyError as e:\n",
    "    raise KeyError(f\"Environment variable {e} is not set. Please set it before running the script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24495a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_timestamps(now):\n",
    "    \"\"\"Get the start and end timestamps.\"\"\"\n",
    "    \n",
    "    start_of_day = now - timedelta(days = 1)\n",
    "    start_timestamp = int(start_of_day.timestamp())\n",
    "    end_timestamp = int(now.timestamp())\n",
    "\n",
    "    return start_timestamp, end_timestamp\n",
    "\n",
    "def get_prompt(prompt_template_identifier = \"80865\"):\n",
    "  \n",
    "    prompt_template_identifier = prompt_template_identifier\n",
    "\n",
    "    url = f\"https://api.promptlayer.com/prompt-templates/{prompt_template_identifier}\"\n",
    "    headers = {\n",
    "        \"X-API-KEY\": PROMPTLAYER_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers = headers)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    messages = data.get(\"prompt_template\", {}).get(\"messages\", {})\n",
    "    for m in messages:\n",
    "        if m.get(\"role\", {}) == \"system\":\n",
    "            system_prompt = m.get(\"content\", [])[0].get(\"text\", \"\")\n",
    "        if m.get(\"role\", {}) == \"user\":\n",
    "            user_prompt = m.get(\"content\", [])[0].get(\"text\", \"\")\n",
    "\n",
    "    if not system_prompt or not user_prompt:\n",
    "        raise ValueError(\"System or User prompt not found in the PromptLayer response.\")\n",
    "\n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "def get_block_number_by_timestamp(target_timestamp, api_key):\n",
    "\n",
    "    url = (f\"https://api.etherscan.io/api?module=block&action=getblocknobytime\"\n",
    "           f\"&timestamp={target_timestamp}&closest=before&apikey={api_key}\")\n",
    "    \n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        \n",
    "        if data[\"status\"] == \"1\":\n",
    "            return int(data[\"result\"])\n",
    "        else:\n",
    "            raise ValueError(f\"Error fetching block number: {data['message']}\")\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"API Request failed: {e}\")\n",
    "\n",
    "def get_block_transactions(block_number, api_key):\n",
    "\n",
    "    url = (f\"https://api.etherscan.io/api?module=proxy&action=eth_getBlockByNumber\"\n",
    "           f\"&tag={hex(block_number)}&boolean=true&apikey={api_key}\")\n",
    "\n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        if 'result' in data and data['result'] and 'transactions' in data['result']:\n",
    "            return data['result']['transactions']\n",
    "        else:\n",
    "            return []\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Warning: Could not fetch block {block_number}. Error: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_and_aggregate_transactions(transactions, target_date):\n",
    "\n",
    "    if not transactions:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(transactions)\n",
    "\n",
    "    numeric_cols = ['gas', 'gasPrice', 'value']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col].apply(lambda x: int(x, 16) if isinstance(x, str) else x), errors = 'coerce')\n",
    "    \n",
    "    df['value'] = df['value'] / 1e18\n",
    "\n",
    "    daily_metrics = {\n",
    "        'metric_date': target_date,\n",
    "        'total_transactions': len(df),\n",
    "        'average_gas_used': df['gas'].mean(),\n",
    "        'total_eth_transferred': df['value'].sum(),\n",
    "        'unique_active_wallets': pd.concat([df['from'], df['to']]).nunique()\n",
    "    }\n",
    "\n",
    "    return df, pd.DataFrame([daily_metrics])\n",
    "\n",
    "def generate_daily_summary(metrics, system_prompt, user_prompt):\n",
    "\n",
    "    print(\"Generating LLM summary...\")\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment = MODEL,\n",
    "        api_version = AZURE_API_VERSION,\n",
    "        azure_endpoint = AZURE_ENDPOINT,\n",
    "        api_key = AZURE_API_KEY,\n",
    "        temperature = 0.2\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"\"\"\n",
    "        Please provide a summary for the Ethereum network activity on {metric_date}.\n",
    "        \n",
    "        Key Metrics:\n",
    "        - Total Transactions: {total_transactions:,.0f}\n",
    "        - Average Gas Used per Transaction: {average_gas_used:,.0f}\n",
    "        - Total ETH Transferred: {total_eth_transferred:,.2f} ETH\n",
    "        - Unique Active Wallets: {unique_active_wallets:,.0f}\n",
    "        \n",
    "        \"\"\" + user_prompt)\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    try:\n",
    "        summary = chain.invoke(metrics)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating LLM summary: {e}\")\n",
    "        return\n",
    "\n",
    "def run_pipeline_for_date(run_date, api_key):\n",
    "    \"\"\"Main function to run the full ETL pipeline for a specific date.\"\"\"\n",
    "\n",
    "    print(f\"\\n--- Starting On-Chain ETL Pipeline for {run_date.strftime('%Y-%m-%d')} ---\")\n",
    "\n",
    "    start_timestamp, end_timestamp = get_day_timestamps(run_date)\n",
    "\n",
    "    print(\"Step 1: Extracting data from Etherscan...\")\n",
    "    try:\n",
    "        start_block = get_block_number_by_timestamp(start_timestamp, ETHERSCAN_API_KEY)\n",
    "        end_block = get_block_number_by_timestamp(end_timestamp, ETHERSCAN_API_KEY)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting block range: {e}. Skipping this date.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing blocks from {start_block} to {end_block}.\")\n",
    "    all_transactions = []\n",
    "    block_numbers = range(start_block, end_block + 1)\n",
    "\n",
    "    # call the API in parallel for each block\n",
    "    with ThreadPoolExecutor(max_workers = 5) as executor:\n",
    "        future_to_block = {executor.submit(get_block_transactions, b, ETHERSCAN_API_KEY): b for b in block_numbers}\n",
    "\n",
    "        for future in as_completed(future_to_block):\n",
    "            block_number = future_to_block[future]\n",
    "            try:\n",
    "                transactions = future.result()\n",
    "                if transactions:\n",
    "                    all_transactions.extend(transactions)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing block {block_number}: {e}\")\n",
    "\n",
    "    print(\"Step 2: Transforming and aggregating data...\")\n",
    "    df, metrics_df = process_and_aggregate_transactions(all_transactions, run_date)\n",
    "\n",
    "    if metrics_df.empty:\n",
    "        print(\"Pipeline finished for this date with no data to save.\")\n",
    "        return\n",
    "\n",
    "    print(\"Step 3: Generating LLM Insights...\")\n",
    "    metrics_dict = metrics_df.to_dict('records')[0]\n",
    "    llm_summary = generate_daily_summary(metrics_dict, system_prompt, user_prompt)\n",
    "    metrics_df['llm_summary'] = llm_summary\n",
    "\n",
    "    print(\"Step 4: Loading data to Csv file...\")\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    filename = f\"daily_metrics_{run_date.strftime('%Y%m%d')}.csv\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    metrics_df.to_csv(output_path, index = False)\n",
    "    print(f\"Successfully saved daily metrics and summary to: {output_path}\")\n",
    "    print(f\"--- Pipeline Finished for {run_date.strftime('%Y-%m-%d')} ---\")\n",
    "\n",
    "    return df, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3eb7c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Starting Daily On-Chain Data Processing Job\n",
      "=====================================================\n",
      "\n",
      "--- Starting On-Chain ETL Pipeline for 2025-08-10 ---\n",
      "Step 1: Extracting data from Etherscan...\n",
      "Processing blocks from 23103849 to 23111003.\n",
      "Step 2: Transforming and aggregating data...\n",
      "Step 3: Generating LLM Insights...\n",
      "Generating LLM summary...\n",
      "Step 4: Loading data to Csv file...\n",
      "Successfully saved daily metrics and summary to: output/daily_metrics_20250810.csv\n",
      "--- Pipeline Finished for 2025-08-10 ---\n",
      "\n",
      "=====================================================\n",
      "All tasks for today completed.\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "print(\"=====================================================\")\n",
    "print(\"Starting Daily On-Chain Data Processing Job\")\n",
    "print(\"=====================================================\")\n",
    "\n",
    "df, metrics_df = run_pipeline_for_date(now, ETHERSCAN_API_KEY)\n",
    "    \n",
    "print(\"\\n=====================================================\")\n",
    "print(\"All tasks for today completed.\")\n",
    "print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f17ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
